{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlfyOXv58bHCAzOvoA9vkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivcoderrr/Shivcoderrr/blob/main/TEXT_CLASSFIER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7c08bd9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dummy DataFrame\n",
        "data = {'text': [\"This is a positive review.\",\n",
        "                 \"I did not like this product.\",\n",
        "                 \"The service was excellent!\",\n",
        "                 \"Terrible experience overall.\",\n",
        "                 \"It was just okay.\"],\n",
        "        'label': [1, 0, 1, 0, 0]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(\"dataset.csv\", index=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9be04e0",
        "outputId": "1e5aabf8-2760-4030-cab2-3565927bb5b9"
      },
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\"dataset.csv\")\n",
        "texts = data['text'].astype(str).tolist()\n",
        "labels = data['label'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Tokenization\n",
        "vocab_size = 10000\n",
        "max_length = 100\n",
        "oov_token = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 64, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.GlobalMaxPool1D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save(\"text_classifier.h5\")\n",
        "import pickle\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "# Predict function\n",
        "def predict_text(text):\n",
        "    with open(\"tokenizer.pkl\", \"rb\") as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    with open(\"label_encoder.pkl\", \"rb\") as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "    model = tf.keras.models.load_model(\"text_classifier.h5\")\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    pred = model.predict(padded_seq)[0][0]\n",
        "\n",
        "    label = label_encoder.inverse_transform([int(pred > 0.5)])\n",
        "    print(f\"Prediction: {label[0]} (confidence: {pred:.2f})\")\n",
        "\n",
        "# Try prediction\n",
        "predict_text(\"I really enjoyed the experience\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.5000 - loss: 0.6920 - val_accuracy: 0.0000e+00 - val_loss: 0.6972\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655ms/step - accuracy: 0.7500 - loss: 0.6892 - val_accuracy: 0.0000e+00 - val_loss: 0.7038\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 1.0000 - loss: 0.6821 - val_accuracy: 0.0000e+00 - val_loss: 0.7088\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.7500 - loss: 0.6778 - val_accuracy: 0.0000e+00 - val_loss: 0.7111\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 1.0000 - loss: 0.6804 - val_accuracy: 0.0000e+00 - val_loss: 0.7136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
            "Prediction: 1 (confidence: 0.51)\n"
          ]
        }
      ]
    }
  ]
}